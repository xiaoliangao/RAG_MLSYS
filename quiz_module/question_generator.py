# quiz_module/question_generator.py

import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
import json
import random
import re
from typing import List, Dict, Any, Optional

# ç”Ÿæˆé…ç½®
GENERATION_CONFIG = {
    "max_new_tokens": 1024,
    "temperature": 0.5,
    "top_p": 0.9,
    "do_sample": True,
}


def _build_question_gen_prompt(context: str, q_type: str = "choice", difficulty: str = "medium") -> List[Dict[str, str]]:
    """
    æ„å»ºé¢˜ç›®ç”Ÿæˆæç¤ºè¯ - ä¼˜åŒ–ç‰ˆ
    
    Args:
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        q_type: é¢˜ç›®ç±»å‹ ("choice" æˆ– "boolean")
        difficulty: éš¾åº¦ç­‰çº§ ("easy", "medium", "hard")
    """
    
    difficulty_instructions = {
        "easy": "åŸºç¡€æ¦‚å¿µå’Œå®šä¹‰ç†è§£",
        "medium": "æ¦‚å¿µåº”ç”¨å’ŒçŸ¥è¯†ç»¼åˆ",
        "hard": "æ·±åº¦åˆ†æå’Œæ‰¹åˆ¤æ€§æ€ç»´"
    }
    
    if q_type == "choice":
        type_instruction = "ä¸€é“å››é€‰ä¸€çš„é€‰æ‹©é¢˜"
        json_format = """
{
  "question": "å®Œæ•´ã€ç‹¬ç«‹çš„é—®é¢˜æè¿°",
  "type": "choice",
  "options": [
    "A. é€‰é¡¹å†…å®¹",
    "B. é€‰é¡¹å†…å®¹",
    "C. é€‰é¡¹å†…å®¹",
    "D. é€‰é¡¹å†…å®¹"
  ],
  "correct_answer_letter": "A",
  "explanation": "è¯¦ç»†è§£é‡Šæ­£ç¡®ç­”æ¡ˆçš„åŸå› ï¼Œå¹¶è¯´æ˜å…¶ä»–é€‰é¡¹ä¸ºä½•é”™è¯¯"
}
"""
        quality_rules = """
**é€‰æ‹©é¢˜è´¨é‡æ ‡å‡†ï¼š**
- å¹²æ‰°é¡¹è¦åˆç†ä½†æ˜ç¡®é”™è¯¯ï¼Œé¿å…äº‰è®®
- é€‰é¡¹é•¿åº¦å’Œå¤æ‚åº¦åº”ç›¸è¿‘
- é¿å…"ä»¥ä¸Šéƒ½å¯¹/éƒ½é”™"ç­‰æ¨¡ç³Šé€‰é¡¹
- æ­£ç¡®ç­”æ¡ˆå¿…é¡»å”¯ä¸€ä¸”æ˜ç¡®"""

    else:  # boolean
        type_instruction = "ä¸€é“åˆ¤æ–­é¢˜"
        json_format = """
{
  "question": "ä¸€ä¸ªæ˜ç¡®çš„é™ˆè¿°å¥ï¼ˆå¯åˆ¤æ–­çœŸå‡ï¼‰",
  "type": "boolean",
  "correct_answer": true,
  "explanation": "è¯¦ç»†è¯´æ˜è¿™ä¸ªé™ˆè¿°ä¸ºä½•æ­£ç¡®/é”™è¯¯ï¼Œå¼•ç”¨ç›¸å…³çŸ¥è¯†ç‚¹"
}
"""
        quality_rules = """
**åˆ¤æ–­é¢˜è´¨é‡æ ‡å‡†ï¼š**
- é™ˆè¿°å¿…é¡»æ˜ç¡®ã€ä¸å«ç³Š
- é¿å…åŒé‡å¦å®šæˆ–å¤æ‚é€»è¾‘
- ä¸ä½¿ç”¨"æ€»æ˜¯"ã€"æ°¸è¿œ"ã€"å®Œå…¨"ç­‰ç»å¯¹è¯ï¼ˆé™¤éç¡®å®å¦‚æ­¤ï¼‰"""

    system_prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•™è‚²æµ‹è¯„ä¸“å®¶ï¼Œæ“…é•¿è®¾è®¡é«˜è´¨é‡çš„å­¦ç§‘æµ‹è¯•é¢˜ç›®ã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
åŸºäºæä¾›çš„æ•™å­¦ææ–™ï¼Œè®¾è®¡{type_instruction}ã€‚
- **éš¾åº¦ç­‰çº§**: {difficulty_instructions[difficulty]}
- **çŸ¥è¯†æ¥æº**: å¿…é¡»ä¸¥æ ¼åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ææ–™

**å…³é”®åŸåˆ™ï¼š**

1. **é¢˜ç›®è‡ªæ´½æ€§** â­
   - é¢˜ç›®è¡¨è¿°å¿…é¡»å®Œæ•´ã€ç‹¬ç«‹ï¼Œä¸ä¾èµ–é¢å¤–èƒŒæ™¯
   - å­¦ç”Ÿæ— éœ€é˜…è¯»åŸå§‹ææ–™å°±èƒ½ç†è§£é¢˜ç›®
   - ç»ä¸ä½¿ç”¨"æ ¹æ®ä¸Šæ–‡"ã€"ææ–™ä¸­æåˆ°"ã€"ä»¥ä¸‹å“ªä¸ª"ç­‰å¼•ç”¨æ€§è¡¨è¿°

2. **çŸ¥è¯†èšç„¦** â­
   - åªè€ƒæŸ¥å­¦ç§‘æ ¸å¿ƒçŸ¥è¯†ï¼ˆæ¦‚å¿µã€åŸç†ã€æ–¹æ³•ã€åº”ç”¨ï¼‰
   - ä¸¥ç¦è€ƒæŸ¥å…ƒä¿¡æ¯ï¼ˆç« èŠ‚å·ã€é¡µç ã€ä½œè€…ã€å‚è€ƒæ–‡çŒ®ç­‰ï¼‰
   - é¢˜ç›®åº”å…·æœ‰æ•™å­¦ä»·å€¼å’Œå®é™…æ„ä¹‰

3. **ç­”æ¡ˆå‡†ç¡®æ€§** â­
   - æ­£ç¡®ç­”æ¡ˆå¿…é¡»åœ¨ä¸Šä¸‹æ–‡ä¸­æœ‰æ˜ç¡®ä¾æ®
   - ä¸ç¼–é€ æˆ–æ¨æµ‹ææ–™å¤–çš„ä¿¡æ¯
   - å¦‚æœææ–™ä¿¡æ¯ä¸è¶³ï¼Œé€‰æ‹©å…¶ä»–çŸ¥è¯†ç‚¹

4. **è¡¨è¾¾è§„èŒƒ** â­
   - ä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„å­¦æœ¯è¯­è¨€
   - é¿å…æ­§ä¹‰ã€æ¨¡ç³Šæˆ–è¿‡äºå£è¯­åŒ–çš„è¡¨è¿°
   - æ•°å­¦å…¬å¼å’Œä¸“ä¸šæœ¯è¯­è¦å‡†ç¡®

{quality_rules}

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
- å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜æˆ–ä»£ç å—æ ‡è®°
- ç¡®ä¿JSONå®Œå…¨æœ‰æ•ˆï¼ˆæ£€æŸ¥å¼•å·ã€é€—å·ã€æ‹¬å·ï¼‰

**JSONæ ¼å¼ç¤ºä¾‹ï¼š**
{json_format}"""

    user_message = f"""**æ•™å­¦ææ–™ï¼š**
{context}

---

è¯·åŸºäºä¸Šè¿°ææ–™ï¼Œç”Ÿæˆä¸€é“{difficulty_instructions[difficulty]}çš„{type_instruction}ã€‚

**è¦æ±‚ï¼š**
- é¢˜ç›®å®Œå…¨ç‹¬ç«‹ï¼Œä¸å¼•ç”¨"ææ–™"æˆ–"ä¸Šæ–‡"
- è€ƒæŸ¥å­¦ç§‘çŸ¥è¯†ï¼Œéå…ƒä¿¡æ¯
- ç­”æ¡ˆæœ‰æ˜ç¡®ä¾æ®
- ç›´æ¥è¿”å›JSONï¼Œæ— é¢å¤–å†…å®¹"""

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message}
    ]


def _parse_llm_json_output(response: str) -> Optional[Dict[str, Any]]:
    """
    ä»LLMè¾“å‡ºä¸­è§£æJSON - å¢å¼ºç‰ˆ
    """
    try:
        response = response.strip()
        
        # ç§»é™¤Markdownä»£ç å—
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0].strip()
        elif "```" in response:
            response = response.split("```")[1].split("```")[0].strip()
        
        # æå–JSONå¯¹è±¡
        json_match = re.search(r'\{[\s\S]*\}', response)
        if json_match:
            response = json_match.group(0)
        
        parsed = json.loads(response)
        
        q_type = parsed.get("type")

        # å¸ƒå°”å‹æ ¼å¼è½¬æ¢
        if q_type == "boolean":
            if "correct_answer" in parsed:
                if not isinstance(parsed["correct_answer"], bool):
                    print(f"âŒ åˆ¤æ–­é¢˜ç­”æ¡ˆå¿…é¡»æ˜¯å¸ƒå°”å€¼")
                    return None
                
                correct_bool = parsed["correct_answer"]
                parsed["options"] = ["æ­£ç¡®", "é”™è¯¯"]
                parsed["correct_answer_index"] = 0 if correct_bool else 1
                del parsed["correct_answer"]
            
            elif "correct_answer_index" not in parsed:
                print(f"âŒ åˆ¤æ–­é¢˜ç¼ºå°‘ç­”æ¡ˆå­—æ®µ")
                return None
        
        # é€‰æ‹©é¢˜æ ¼å¼è½¬æ¢
        elif q_type == "choice":
            if "correct_answer_letter" in parsed:
                letter = parsed["correct_answer_letter"].upper().strip()
                letter_map = {"A": 0, "B": 1, "C": 2, "D": 3}
                
                index = letter_map.get(letter)
                
                if index is None:
                    print(f"âŒ ç­”æ¡ˆæ ‡è¯†å¿…é¡»æ˜¯A/B/C/D")
                    return None
                
                parsed["correct_answer_index"] = index
                del parsed["correct_answer_letter"]
            
            elif "correct_answer_index" not in parsed:
                print(f"âŒ é€‰æ‹©é¢˜ç¼ºå°‘ç­”æ¡ˆå­—æ®µ")
                return None

        # ç»Ÿä¸€éªŒè¯
        required_fields = ["question", "type", "options", "correct_answer_index", "explanation"]
        if not all(field in parsed for field in required_fields):
            missing = [f for f in required_fields if f not in parsed]
            print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing}")
            return None
        
        if not isinstance(parsed["options"], list) or len(parsed["options"]) == 0:
            print(f"âŒ é€‰é¡¹æ ¼å¼é”™è¯¯")
            return None
        
        if not isinstance(parsed["correct_answer_index"], int):
            print(f"âŒ ç­”æ¡ˆç´¢å¼•å¿…é¡»æ˜¯æ•´æ•°")
            return None
        
        if parsed["correct_answer_index"] < 0 or parsed["correct_answer_index"] >= len(parsed["options"]):
            print(f"âŒ ç­”æ¡ˆç´¢å¼•è¶…å‡ºèŒƒå›´")
            return None
        
        return parsed
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"âŒ è§£æå¼‚å¸¸: {e}")
        return None


def _validate_question_quality(question: Dict[str, Any]) -> tuple[bool, str]:
    """
    éªŒè¯é¢˜ç›®è´¨é‡
    
    Returns:
        (is_valid, reason)
    """
    # æ£€æŸ¥é—®é¢˜é•¿åº¦
    if len(question["question"]) < 10:
        return False, "é—®é¢˜è¿‡çŸ­"
    
    if len(question["question"]) > 500:
        return False, "é—®é¢˜è¿‡é•¿"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¼•ç”¨æ€§è¯è¯­ï¼ˆè´¨é‡çº¢çº¿ï¼‰
    forbidden_phrases = [
        "æ ¹æ®ä¸Šæ–‡", "æ ¹æ®ææ–™", "æ ¹æ®ä¸Šè¿°", "ææ–™ä¸­", "æ–‡ä¸­", 
        "ä¸Šé¢æåˆ°", "ä»¥ä¸‹å“ªä¸ª", "è¯¥ä¹¦", "æœ¬æ–‡", "ä½œè€…è®¤ä¸º"
    ]
    
    question_text = question["question"].lower()
    for phrase in forbidden_phrases:
        if phrase in question_text:
            return False, f"é¢˜ç›®åŒ…å«å¼•ç”¨æ€§è¡¨è¿°: {phrase}"
    
    # æ£€æŸ¥é€‰é¡¹
    options = question["options"]
    if question["type"] == "choice":
        if len(options) != 4:
            return False, f"é€‰æ‹©é¢˜åº”æœ‰4ä¸ªé€‰é¡¹ï¼Œå®é™…{len(options)}ä¸ª"
        
        # æ£€æŸ¥é€‰é¡¹é‡å¤
        option_texts = [opt.split(". ", 1)[-1] if ". " in opt else opt for opt in options]
        if len(set(option_texts)) != len(option_texts):
            return False, "é€‰é¡¹å­˜åœ¨é‡å¤"
        
        # æ£€æŸ¥é€‰é¡¹é•¿åº¦
        for opt in options:
            if len(opt) < 2:
                return False, "é€‰é¡¹è¿‡çŸ­"
    
    # æ£€æŸ¥è§£é‡Š
    if len(question["explanation"]) < 20:
        return False, "è§£é‡Šè¿‡äºç®€çŸ­"
    
    return True, "OK"


@torch.no_grad()
def generate_quiz_questions(
    retriever: BaseRetriever, 
    tokenizer: AutoTokenizer, 
    model: AutoModelForCausalLM, 
    device: str,
    num_choice: int = 3, 
    num_boolean: int = 2,
    difficulty: str = "medium",
    max_retries: int = 3,
    use_clustering: bool = True
) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆæµ‹éªŒé¢˜ç›® - æ”¯æŒä¸»é¢˜èšç±»
    
    Args:
        retriever: æ£€ç´¢å™¨
        tokenizer: åˆ†è¯å™¨
        model: è¯­è¨€æ¨¡å‹
        device: è®¾å¤‡
        num_choice: é€‰æ‹©é¢˜æ•°é‡
        num_boolean: åˆ¤æ–­é¢˜æ•°é‡
        difficulty: éš¾åº¦ç­‰çº§
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        use_clustering: æ˜¯å¦ä½¿ç”¨ä¸»é¢˜èšç±»ï¼ˆæ¨èå¼€å¯ï¼‰
    
    Returns:
        é¢˜ç›®åˆ—è¡¨
    """
    
    questions = []
    failed_count = 0
    
    num_to_generate = num_choice + num_boolean
    
    try:
        all_docs = []
        
        # å°è¯•ä»æ£€ç´¢å™¨è·å–æ–‡æ¡£
        if hasattr(retriever, 'retrievers') and len(retriever.retrievers) > 1:
            bm25_retriever = retriever.retrievers[1]
            if hasattr(bm25_retriever, 'documents'):
                print("âœ“ ä½¿ç”¨æ–‡æ¡£æ± é‡‡æ ·")
                all_docs = bm25_retriever.documents
        
        # å›é€€åˆ°æŸ¥è¯¢
        if not all_docs:
            print("âš ï¸ ä½¿ç”¨æŸ¥è¯¢é‡‡æ ·")
            base_queries = [
                "æ ¸å¿ƒæ¦‚å¿µå’Œå…³é”®çŸ¥è¯†ç‚¹",
                "é‡è¦ç®—æ³•å’Œæ–¹æ³•",
                "åŸºæœ¬åŸç†å’Œå®šç†",
                "å…·ä½“å®ç°å’ŒæŠ€æœ¯ç»†èŠ‚",
                "ä¸åŒæ–¹æ³•çš„å¯¹æ¯”åˆ†æ",
                "ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯",
                "é«˜çº§æŠ€å·§å’Œæ³¨æ„äº‹é¡¹"
            ]
            queries = random.sample(base_queries, k=min(len(base_queries), 3))
            
            seen_content = set()
            for query in queries:
                docs = retriever.invoke(query)
                for doc in docs:
                    content_hash = hash(doc.page_content)
                    if content_hash not in seen_content:
                        all_docs.append(doc)
                        seen_content.add(content_hash)

        if not all_docs:
            st.error("âŒ çŸ¥è¯†åº“ä¸ºç©º")
            return []
        
        # === æ ¸å¿ƒæ”¹è¿›ï¼šæ™ºèƒ½æ–‡æ¡£é‡‡æ · ===
        if use_clustering and len(all_docs) > num_to_generate * 2:
            print(f"ğŸ¯ å¯ç”¨æ™ºèƒ½ä¸»é¢˜èšç±»é‡‡æ ·...")
            
            try:
                from quiz_module.topic_clustering import smart_document_sampling
                
                # ä½¿ç”¨K-Meansèšç±»ï¼ˆæ›´å¿«ï¼‰
                source_chunks = smart_document_sampling(
                    documents=all_docs,
                    num_samples=num_to_generate,
                    method="kmeans"
                )
                
                print(f"âœ“ ä¸»é¢˜èšç±»é‡‡æ ·å®Œæˆï¼Œè·å¾—{len(source_chunks)}ä¸ªé«˜è¦†ç›–æ ·æœ¬")
                
            except Exception as e:
                print(f"âš ï¸ èšç±»é‡‡æ ·å¤±è´¥: {e}ï¼Œå›é€€åˆ°éšæœºé‡‡æ ·")
                # èšç±»å¤±è´¥ï¼Œç«‹å³å›é€€åˆ°éšæœºé‡‡æ ·
                if len(all_docs) < num_to_generate:
                    print(f"âš ï¸ æ–‡æ¡£ä¸è¶³ï¼Œè¿›è¡Œæœ‰æ”¾å›é‡‡æ ·")
                    source_chunks = random.choices(all_docs, k=num_to_generate)
                else:
                    source_chunks = random.sample(all_docs, k=num_to_generate)
        
        # é™çº§åˆ°éšæœºé‡‡æ · (å¦‚æœç¦ç”¨äº†èšç±»ï¼Œæˆ–è€…æ–‡æ¡£æ•°ä¸è¶³)
        else:
            print("âœ“ ä½¿ç”¨éšæœºé‡‡æ ·ï¼ˆèšç±»æœªå¯ç”¨æˆ–æ–‡æ¡£ä¸è¶³ï¼‰")
            if len(all_docs) < num_to_generate:
                print(f"âš ï¸ æ–‡æ¡£ä¸è¶³ï¼Œè¿›è¡Œæœ‰æ”¾å›é‡‡æ ·")
                source_chunks = random.choices(all_docs, k=num_to_generate)
            else:
                source_chunks = random.sample(all_docs, k=num_to_generate)
            
    except Exception as e:
        st.error(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
        return []

    total_steps = num_choice + num_boolean
    progress_bar = st.progress(0, text="ğŸ¯ å¼€å§‹ç”Ÿæˆé¢˜ç›®...")
    
    # ç”Ÿæˆé€‰æ‹©é¢˜
    for i in range(num_choice):
        chunk = source_chunks[i]
        success = False
        
        for retry in range(max_retries):
            try:
                messages = _build_question_gen_prompt(chunk.page_content, "choice", difficulty)
                
                text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
                inputs = tokenizer(text, return_tensors="pt").to(device)
                
                outputs = model.generate(**inputs, **GENERATION_CONFIG)
                response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
                
                if "assistant" in response_text:
                    response_text = response_text.split("assistant")[-1].strip()
                
                parsed_q = _parse_llm_json_output(response_text)
                
                if parsed_q:
                    is_valid, reason = _validate_question_quality(parsed_q)
                    if is_valid:
                        questions.append(parsed_q)
                        success = True
                        break
                    else:
                        print(f"âš ï¸ è´¨é‡ä¸åˆæ ¼ (é‡è¯• {retry+1}/{max_retries}): {reason}")
                else:
                    print(f"âš ï¸ è§£æå¤±è´¥ (é‡è¯• {retry+1}/{max_retries})")
                
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆå¼‚å¸¸ (é‡è¯• {retry+1}/{max_retries}): {e}")
        
        if not success:
            failed_count += 1
            print(f"âŒ é€‰æ‹©é¢˜ {i+1} å¤±è´¥")
        
        progress_text = f"ğŸ“ ç”Ÿæˆä¸­... ({i+1}/{total_steps}) é€‰æ‹©é¢˜"
        if failed_count > 0:
            progress_text += f" [å¤±è´¥: {failed_count}]"
        progress_bar.progress((i + 1) / total_steps, text=progress_text)

    # ç”Ÿæˆåˆ¤æ–­é¢˜
    for i in range(num_boolean):
        chunk = source_chunks[num_choice + i]
        success = False
        
        for retry in range(max_retries):
            try:
                messages = _build_question_gen_prompt(chunk.page_content, "boolean", difficulty)
                
                text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
                inputs = tokenizer(text, return_tensors="pt").to(device)
                
                outputs = model.generate(**inputs, **GENERATION_CONFIG)
                response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
                
                if "assistant" in response_text:
                    response_text = response_text.split("assistant")[-1].strip()
                
                parsed_q = _parse_llm_json_output(response_text)
                
                if parsed_q:
                    is_valid, reason = _validate_question_quality(parsed_q)
                    if is_valid:
                        questions.append(parsed_q)
                        success = True
                        break
                    else:
                        print(f"âš ï¸ è´¨é‡ä¸åˆæ ¼ (é‡è¯• {retry+1}/{max_retries}): {reason}")
                else:
                    print(f"âš ï¸ è§£æå¤±è´¥ (é‡è¯• {retry+1}/{max_retries})")
                    
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆå¼‚å¸¸ (é‡è¯• {retry+1}/{max_retries}): {e}")
        
        if not success:
            failed_count += 1
            print(f"âŒ åˆ¤æ–­é¢˜ {i+1} å¤±è´¥")
        
        progress_text = f"ğŸ“ ç”Ÿæˆä¸­... ({num_choice + i + 1}/{total_steps}) åˆ¤æ–­é¢˜"
        if failed_count > 0:
            progress_text += f" [å¤±è´¥: {failed_count}]"
        progress_bar.progress((num_choice + i + 1) / total_steps, text=progress_text)

    progress_bar.empty()
    
    # ç»“æœç»Ÿè®¡
    success_count = len(questions)
    if success_count > 0:
        st.success(f"âœ… æˆåŠŸç”Ÿæˆ {success_count} é“é¢˜ç›®")
        if failed_count > 0:
            st.warning(f"âš ï¸ {failed_count} é“é¢˜ç›®å¤±è´¥")
    else:
        st.error("âŒ é¢˜ç›®ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
    
    return questions